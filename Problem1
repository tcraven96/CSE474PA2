def ldaLearn(X,y):
    # Inputs
    # X - a N x d matrix with each row corresponding to a training example
    # y - a N x 1 column vector indicating the labels for each training example
    #
    # Outputs
    # means - A k x d matrix containing learnt means for each of the k classes
    # covmat - A single d x d learnt covariance matrix 
    
    # IMPLEMENT THIS METHOD

    N = len(X)
    d = len(X[0])
    k = int(y.max())

    means = np.zeros((int(k), int(d)))
    sum = np.zeros((1, d))
    count = 0
    covmat = np.zeros((int(d), int(d)))

    for cls in range(int(k)):
        for array in range(N):
            if y[array] == cls+1:
                sum[0,:] = sum[0,:] + X[array, :]
                count = count + 1
        means[cls, :] = sum[0,:] / count
        sum[:,:] = 0
        count = 0

    total_mean = np.zeros((1,int(d)))
    # print(total_mean.shape)
    total_mean[0,:] = np.mean(X, axis=0)
    # print(total_mean.shape)
    ssum = np.zeros((d,d))
    for array in range(N):
        A = np.zeros((1, int(d)))
        A[0, :] = X[array, :] - total_mean
        ssum = ssum + np.dot((A).T, (A))
    covmat = ssum / N

    #LDA covariance 구할 때 mean도 class 구분 없이 계산해서 구하기?

    return means,covmat

def qdaLearn(X,y):
    # Inputs
    # X - a N x d matrix with each row corresponding to a training example
    # y - a N x 1 column vector indicating the labels for each training example
    #
    # Outputs
    # means - A k x d matrix containing learnt means for each of the k classes
    # covmats - A list of k d x d learnt covariance matrices for each of the k classes

    # IMPLEMENT THIS METHOD

    N = len(X)
    d = len(X[0])
    k = int(y.max())

    means = np.zeros((k,d))
    sum = np.zeros((1, d))
    count = 0
    covmats = np.zeros((k,d,d))     #3-dimension

    for cls in range(k):
        for array in range(N):
            if y[array] == cls+1:
                sum[0,:] = sum[0,:] + X[array,:]
                count = count +1
        means[cls, :] = sum[0,:] / count
        sum[:,:] = 0
        count = 0

    ssum = np.zeros((d,d))
    for cls in range(k):
        for array in range(N):
            A = np.zeros((1,int(d)))
            if y[array] == cls+1:
                A[0,:] = X[array,:] - means[cls,:]
                ssum = ssum + np.dot( A.T , A )
                count = count +1
        covmats[cls, :, :] = ssum[:,:] / count
        ssum[:,:] = 0
        count = 0


    #자료형 맞추기 -> mean 구할 때 끊어지지 않는지
    #N, N-1 등 시작 포인트 0/1 구분
    #for i in range(k) 하면 i가 1부터 k까지 or 0부터 k-1까지?


    return means,covmats

def ldaTest(means,covmat,Xtest,ytest):
    # Inputs
    # means, covmat - parameters of the LDA model
    # Xtest - a N x d matrix with each row corresponding to a test example
    # ytest - a N x 1 column vector indicating the labels for each test example
    # Outputs
    # acc - A scalar accuracy value
    # ypred - N x 1 column vector indicating the predicted labels

    # IMPLEMENT THIS METHOD

    k = len(means)
    N = len(Xtest)
    d = len(Xtest[0])
    P = np.zeros((int(k), 1))
    ypred = np.zeros((int(N), 1))

    for i in range(N):
        for j in range(k):
            B = np.zeros((1,int(d)))
            B[0,:] = Xtest[i, :] - means[j, :]
            # P[j] = (Xtest[i, :] - means[j, :]) * inv(covmat) * np.transpose(Xtest[i, :] - means[j, :])
            # print(covmat.shape)
            # print(B.shape)
            P[j] = np.dot( B, np.dot(inv(covmat), B.T) )
            # print(P[j])
        pred_cls = np.argmin(P)
        # print(pred_cls)
        ypred[i] = pred_cls + 1
        # print(ypred)

    acc = np.mean((ypred == ytest).astype(float)) * 100

    return acc,ypred

def qdaTest(means,covmats,Xtest,ytest):
    # Inputs
    # means, covmats - parameters of the QDA model
    # Xtest - a N x d matrix with each row corresponding to a test example
    # ytest - a N x 1 column vector indicating the labels for each test example
    # Outputs
    # acc - A scalar accuracy value
    # ypred - N x 1 column vector indicating the predicted labels

    # IMPLEMENT THIS METHOD

    k = len(means)
    N = len(Xtest)
    d = len(Xtest[0])
    P = np.zeros((int(k),1))
    ypred = np.zeros((int(N),1))

    for i in range(N):
        for j in range(k):
            B = np.zeros((1, int(d)))
            B[0,:] = Xtest[i,:]-means[j,:]
            # print(covmats[j,:,:])
            # print(det(covmats[j,:,:]))
            # print(sqrt(det(covmats[j,:,:])))
            P[j] = ( 1/sqrt(det(covmats[j, :, :])) ) * np.exp(-np.dot( B, np.dot(inv(covmats[j,:,:]), B.T) ) /2)
        cls = np.argmax(P)
        ypred[i] = cls + 1

    acc = np.mean((ypred == ytest).astype(float)) * 100

    return acc,ypred
